# -*- coding: utf-8 -*-
"""Modelo_de_Partidos_PoliticosNB_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10C9P45LtkB7TjSA_K13WJoBxWamnvK9P

Fase 1: Importar las dependencias
"""

#instalamos las librerias
!pip install clean-text[gpl]
!pip install py4j
!pip install -q findspark
!pip install tqdm 
!pip install plotly 
!pip install pyspark==2.4.0

!apt-get update

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://www.dropbox.com/s/96rr4avobbz9a1p/spark-2.4.0-bin-hadoop2.7.tar
!tar xf spark-2.4.0-bin-hadoop2.7.tar

#importamos la librerias necesarias para el preprocesamiento
# %matplotlib inline
from nltk import TweetTokenizer
from sklearn.metrics import roc_curve,auc
import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
import re
from string import punctuation
from cleantext import clean
import os
import matplotlib.pyplot as plt
from gensim.models import KeyedVectors
from sklearn.datasets import fetch_20newsgroups

from pyspark.sql import SparkSession
from pyspark import SparkContext
from pyspark.sql.types import *
from pyspark.sql import *
from pyspark.sql import Row
from pyspark.sql import functions as func
from pyspark.mllib.regression import LabeledPoint
from pyspark.mllib.regression import LinearRegressionModel
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.feature import  SQLTransformer
from pyspark.ml.evaluation import  BinaryClassificationEvaluator
from pyspark.ml.classification import NaiveBayes
from pyspark.mllib.evaluation import MulticlassMetrics
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.feature import (VectorAssembler,StringIndexer,StandardScaler,
                                OneHotEncoderEstimator,OneHotEncoder, 
                                VectorIndexer, IndexToString,
                                HashingTF, Tokenizer)
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml import Pipeline, PipelineModel
from pyspark.sql import Row
from pyspark.ml.classification import LinearSVC,OneVsRest,LogisticRegression
from pyspark.ml.clustering import KMeans
from pyspark.ml.evaluation import ClusteringEvaluator

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.0-bin-hadoop2.7"

import findspark
findspark.init("/content/spark-2.4.0-bin-hadoop2.7")

"""Fase 2: Pre Procesado de Datos"""

# !wget https://www.dropbox.com/s/o8eq5kzpcl7ejpv/AlDataset.csv
# !wget https://www.dropbox.com/s/oeemdkwkqvlb1rk/PartidoMoradoPEtrain3.csv
# !wget https://www.dropbox.com/s/41errlqkbihmcc8/AlDatasetTassF.csv
# !wget https://www.dropbox.com/s/bvx5gozhfur6igo/AlDataset3.csv
!wget https://www.dropbox.com/s/np2v706jyz4yz44/data_extended.csv

# funcion para la matriz de confusion
def plot_matrix_confusion(lr_cv_predictions,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
  from numpy import array
  import itertools
  
  class_temp = lr_cv_predictions.select("label").groupBy("label")\
                              .count().sort('count', ascending=False).toPandas()
  class_temp = class_temp["label"].tolist()
  class_names = list(map(str, class_temp))
  
    
  predictions_and_labels = lr_cv_predictions.select("prediction", "label").rdd.map(lambda r: (float(r[0]), float(r[1])))
  metrics = MulticlassMetrics(predictions_and_labels)
  confusion_matrix = metrics.confusionMatrix().toArray()
  met_list = array([[int(x[0]), int(x[1]),int(x[2])] for x in confusion_matrix])

    
  cm = met_list
  classes = class_names
  if normalize:
      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

  plt.imshow(cm, interpolation='nearest', cmap=cmap)
  plt.title(title)
  plt.colorbar()
  tick_marks = np.arange(len(classes))
  plt.xticks(tick_marks, classes, rotation=45)
  plt.yticks(tick_marks, classes)

  fmt = '.2f' if normalize else 'd'
  thresh = cm.max() / 2.
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
      plt.text(j, i, format(cm[i, j], fmt),
               horizontalalignment="center",
               color="white" if cm[i, j] > thresh else "black")

  plt.tight_layout()
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()

def plot_roc_curve2(cv_prediction):
  #PREDICTIONS
  predictions_pddf = cv_prediction.select('prediction','label').toPandas()
  prob = predictions_pddf["prediction"] 
  fpr, tpr, thresholds = roc_curve(predictions_pddf['label'], prob, pos_label=1);
  roc_auc = auc(fpr, tpr)

  # PLOT ROC CURVES
  plt.figure(figsize=(5,5))
  plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
  plt.plot([0, 1], [0, 1], 'k--')
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.05])
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('ROC Curve')
  plt.legend(loc="lower right")
  plt.show()

def get_multiclass_evaluator(prediction):
  lr_multi_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction')

  # Accuracy
  lr_accuracy = lr_multi_evaluator.evaluate(prediction, {lr_multi_evaluator.metricName: "accuracy"})
  print("Accuracy: {:.2f}".format(lr_accuracy))

  # f1
  f1 = lr_multi_evaluator.evaluate(prediction, {lr_multi_evaluator.metricName: "f1"})
  print("f1: {:.2f}".format(f1))

  # Precision
  wp = lr_multi_evaluator.evaluate(prediction, {lr_multi_evaluator.metricName: "weightedPrecision"})
  print("Precision: {:.2f}".format(wp))

  # Recall
  wr = lr_multi_evaluator.evaluate(prediction, {lr_multi_evaluator.metricName: "weightedRecall"})
  print("Recall: {:.2f}".format(wr))
  
  return lr_multi_evaluator

def get_tunning_hiperparameter(grid, cv_model):
  bestPipeline = cv_model.bestModel
  bestLRModel = bestPipeline.stages[-1]
  result = {param.name: bestLRModel.getOrDefault(bestLRModel.getParam(param.name)) for param in grid[0]}
  return result

spark = SparkSession.builder.master("local[*]").appName("Pricing").getOrCreate()

path ="data_extended.csv"

data = pd.read_csv(
    path,
   error_bad_lines=False,
)

stop_words=['a', 'actualmente', 'adelante', 'además', 'afirmó', 'agregó', 'ahí', 'ahora',
    'cc', 'pa', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',
    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'al',
    'algo', 'algún', 'algún', 'alguna', 'algunas', 'alguno', 'algunos',
    'alrededor', 'ambos', 'ampleamos', 'añadió', 'ante', 'anterior', 'antes',
    'apenas', 'aproximadamente', 'aquel', 'aquellas', 'aquellos', 'aqui',
    'aquí', 'arriba', 'aseguró', 'así', 'atras', 'aún', 'aunque', 'ayer',
    'bajo', 'bastante', 'bien', 'buen', 'buena', 'buenas', 'bueno', 'buenos',
    'cada', 'casi', 'cerca', 'cierta', 'ciertas', 'cierto', 'ciertos', 'cinco',
    'comentó', 'como', 'cómo', 'con', 'conocer', 'conseguimos', 'conseguir',
    'considera', 'consideró', 'consigo', 'consigue', 'consiguen', 'consigues',
    'contra', 'cosas', 'creo', 'cual', 'cuales', 'cualquier', 'cuando',
    'cuanto', 'cuatro', 'cuenta', 'da', 'dado', 'dan', 'dar', 'de', 'debe',
    'deben', 'debido', 'decir', 'dejó', 'del', 'demás', 'dentro', 'desde',
    'después', 'dice', 'dicen', 'dicho', 'dieron', 'diferente', 'diferentes',
    'dijeron', 'dijo', 'dio', 'donde', 'dos', 'durante', 'e', 'ejemplo', 'el',
    'de', 'la', 'el', 'porfas', 't', 'p', 'd', 'est',
    'él', 'ella', 'ellas', 'ello', 'ellos', 'embargo', 'empleais', 'emplean',
    'emplear', 'empleas', 'empleo', 'en', 'encima', 'encuentra', 'entonces',
    'entre', 'era', 'eramos', 'eran', 'eras', 'eres', 'es', 'esa', 'esas',
    'ese', 'eso', 'esos', 'esta', 'ésta', 'está', 'estaba', 'estaban',
    'estado', 'estais', 'estamos', 'estan', 'están', 'estar', 'estará',
    'estas', 'éstas', 'este', 'éste', 'esto', 'estos', 'éstos', 'estoy',
    'estuvo', 'ex', 'existe', 'existen', 'explicó', 'expresó', 'fin', 'fue',
    'fuera', 'fueron', 'fui', 'fuimos', 'gran', 'grandes', 'gueno', 'ha',
    'haber', 'había', 'habían', 'habrá', 'hace', 'haceis', 'hacemos', 'hacen',
    'hacer', 'hacerlo', 'haces', 'hacia', 'haciendo', 'hago', 'han', 'hasta',
    'hay', 'haya', 'he', 'hecho', 'hemos', 'hicieron', 'hizo', 'hoy', 'hubo',
    'igual', 'incluso', 'indicó', 'informó', 'intenta', 'intentais',
    'intentamos', 'intentan', 'intentar', 'intentas', 'intento', 'ir', 'junto',
    'la', 'lado', 'largo', 'las', 'le', 'les', 'llegó', 'lleva', 'llevar',
    'lo', 'los', 'luego', 'lugar', 'manera', 'manifestó', 'más', 'mayor', 'me',
    'mediante', 'mejor', 'mencionó', 'menos', 'mi', 'mientras', 'mio', 'misma',
    'mismas', 'mismo', 'mismos', 'modo', 'momento', 'mucha', 'muchas', 'mucho',
    'muchos', 'muy', 'nada', 'nadie', 'ni', 'ningún', 'ninguna', 'ningunas',
    'ninguno', 'ningunos', 'nos', 'nosotras', 'nosotros', 'nuestra',
    'nuestras', 'nuestro', 'nuestros', 'nueva', 'nuevas', 'nuevo', 'nuevos',
    'nunca', 'o', 'ocho', 'otra', 'otras', 'otro', 'otros', 'para', 'parece',
    'parte', 'partir', 'pasada', 'pasado', 'pero', 'pesar', 'poca', 'pocas',
    'poco', 'pocos', 'podeis', 'podemos', 'poder', 'podrá', 'podrán', 'podria',
    'podría', 'podriais', 'podriamos', 'podrian', 'podrían', 'podrias',
    'poner', 'por', 'porque', 'por qué', 'posible', 'primer', 'primera',
    'primero', 'primeros', 'principalmente', 'propia', 'propias', 'propio',
    'propios', 'próximo', 'próximos', 'pudo', 'pueda', 'puede', 'pueden',
    'puedo', 'pues', 'que', 'qué', 'quedó', 'queremos', 'quien', 'quién',
    'quienes', 'quiere', 'realizado', 'realizar', 'realizó', 'respecto',
    'sabe', 'sabeis', 'sabemos', 'saben', 'saber', 'sabes', 'se', 'sea',
    'sean', 'según', 'segunda', 'segundo', 'seis', 'señaló', 'ser', 'será',
    'serán', 'sería', 'si', 'sí', 'sido', 'siempre', 'siendo', 'siete',
    'sigue', 'siguiente', 'sin', 'sino', 'sobre', 'sois', 'sola', 'solamente',
    'solas', 'solo', 'sólo', 'solos', 'somos', 'son', 'soy', 'su', 'sus',
    'tal', 'también', 'tampoco', 'tan', 'tanto', 'tendrá', 'tendrán', 'teneis',
    'tenemos', 'tener', 'tenga', 'tengo', 'tenía', 'tenido', 'tercera',
    'tiempo', 'tiene', 'tienen', 'toda', 'todas', 'todavía', 'todo', 'todos',
    'total', 'trabaja', 'trabajais', 'trabajamos', 'trabajan', 'trabajar',
    'trabajas', 'trabajo', 'tras', 'trata', 'través', 'tres', 'tuvo', 'tuyo',
    'tu', 'te', 'pq', 'mas', 'qie', 'us', 'has', 'ti', 'ahi', 'mis', 'tus',
    'do', 'X', 'Ven', 'mo', 'Don', 'dia', 'PT', 'sua', 'q', 'x', 'i', 
    'última', 'últimas', 'ultimo', 'último', 'últimos', 'un', 'una', 'unas',
    'uno', 'unos', 'usa', 'usais', 'usamos', 'usan', 'usar', 'usas', 'uso',
    'usted', 'va', 'vais', 'valor', 'vamos', 'van', 'varias', 'varios', 'vaya',
    'veces', 'ver', 'verdad', 'verdadera', 'verdadero', 'vez', 'vosotras',
    'n', 's', 'of', 'c', 'the', 'm', 'qu', 'to', 'as', 'is',
    'asi', 'via', 'sera', 'tambien', 'vosotros', 'voy', 'y', 'ya', 'yo']

DIACRITICAL_VOWELS = [('á','a'), ('é','e'), ('í','i'), ('ó','o'), ('ú','u'), ('ü','u')]
SLANG = [('d','de'), ('[qk]','que'), ('xo','pero'), ('xa', 'para'), ('[xp]q','porque'),('es[qk]', 'es que'),
              ('fvr','favor'),('(xfa|xf|pf|plis|pls|porfa)', 'por favor'), ('dnd','donde'), ('tb', 'también'),
              ('(tq|tk)', 'te quiero'), ('(tqm|tkm)', 'te quiero mucho'), ('x','por'), ('\+','mas'),
              ('piña','mala suerte'),('agarre','adulterio'),('ampay','verguenza'),('bacan','alegria'),
              ('bamba','falsificado'),('cabeceador','ladron'),('cabro','homosexual'),('cachaciento','burlon'),
              ('calabacita','tonta'),('caleta','secreto'),('cabro','homosexual'),('cana','carcel'),
              ('chucha','molestia'),('choro','ladron'),('conchán','conchudo'),('cutra','ilicito'),
              ('dark','horrible'),('lenteja','torpe'),('lorna','tonto'),('mancar','morir'),
              ('monse','tonto'),('lenteja','torpe'),('lorna','tonto'),('mancar','morir'),('piñata','mala suerte')
              ]

def text_to_wordlist(text, remove_stop_words=True, stem_words=False):
    # limpiar el  texto
    text = str(text).strip()
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"#\S+", "", text)
    #remplazar los acentos
    for s,t in DIACRITICAL_VOWELS:
        text = re.sub(r'{0}'.format(s), t, text)
   #remplazar el SLANG
    for s,t in SLANG:
        text = re.sub(r'\b{0}\b'.format(s), t, text)
    text = re.sub(r"@[A-Za-z0-9]+", ' ', text)
    text = re.sub(r"[^A-Za-z0-9]", " ", text)
    text = re.sub(r"\'s", " ", text)
    text = re.sub(r"\0s", "0", text)
    text = re.sub(r" 9 11 ", "911", text)
    text = re.sub(r"e-mail", "email", text)
    text = re.sub(r"\0rs ", " rs ", text) 
    text = re.sub(r"gps", "GPS", text)
    text = re.sub(r"gst", "GST", text)
   #convertir a minusculas
    text = text.lower()
    # Remove punctuation from text
    text = ''.join([c for c in text if c not in punctuation ])

    # remover stop words
    if remove_stop_words:
        text = text.split()
        text = [w for w in text if not w in stop_words and len(w)>2]
        text = " ".join(text)
    text = re.sub(r' {2,}' , ' ', text)
    return(text.strip())

data_test['label'] = data['POS'].map({"N":0, "NEU":1, "P":2, "NN":0})
data_test['label'].value_counts()

"""Removemos valores faltantes, si los hubiera"""

df1.fillna(value='', inplace=True)
df1.dropna(inplace=True)

question_list = list()
for question in data_test.full_text:
  question_list.append(text_to_wordlist(str(question).strip()))
df1 = pd.DataFrame(question_list, columns =['full_text']) 
df1["polaridad"] = data_test['POS'].tolist()

"""

Fase 3: Construción del modelo

"""

#eliminar duplicados
dataframe=spark.createDataFrame(df1, ["text", "category"])\
               .filter(func.col("category").isin(["N", "P","NEU"]))\
               .withColumn("id", func.monotonically_increasing_id())\
               .withColumn("label",  (func.when(func.col("category")=="N",0)\
                                    .when(func.col("category")=="P",2)\
                                     .otherwise(1)).cast("double"))\
              .dropDuplicates()

id_columns = ["id"]
categorial_columns = ["text"]
numerical_columns = []
label_columns = ["label"]

#naive Bayes
train_data, valid_data = dataframe.randomSplit([0.7, 0.3])
tokenizer = Tokenizer(inputCol="text", outputCol="words")
hashingTF = HashingTF(inputCol="words", outputCol="features")

nb = NaiveBayes(labelCol="label", featuresCol="features")
nb_pipeline = Pipeline(stages=[tokenizer, hashingTF, nb])

model = nb_pipeline.fit(train_data)
pr = model.transform(valid_data)

nb_evaluator = get_multiclass_evaluator(pr)

"""Busqueda de hiperparámetros"""

nb_paramGrid = (ParamGridBuilder()
               .addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])
               .build())

nb_crossval = CrossValidator(estimator=nb_pipeline, 
                             estimatorParamMaps=nb_paramGrid, 
                             evaluator=nb_evaluator, 
                             numFolds=5)
nb_cv_model = nb_crossval.fit(train_data)
nb_cv_prediction = nb_cv_model.bestModel.transform(valid_data)

"""Guardamos el mejor modelo"""

nb_cv_model.bestModel.write().overwrite().save("data/model/CVModel_NB")
#nb_cv_model.bestModel.write().overwrite().save("drive/My Drive/model/CVModel_NB")

!ls "data/model/"

!zip -r models_nb.zip data/

from google.colab import files
files.download("models_nb.zip")

"""Model Evaluation

"""

nb_cv_multiclass_evaluator = get_multiclass_evaluator(nb_cv_prediction)

get_tunning_hiperparameter(nb_paramGrid, nb_cv_model)

plot_matrix_confusion(nb_cv_prediction)

plot_roc_curve2(nb_cv_prediction)

"""Paso 4: Aplicación y Evaluación"""

df1_test = df1.copy()
del df1_test["polaridad"]

#Donde N=0 y P=1
dataframe=spark.createDataFrame(df1_test, ["text"])\
               .withColumn("id", func.monotonically_increasing_id())\
               .dropDuplicates()

loadedPipeline = PipelineModel.read().load("data/model/CVModel_NB")
predictions = loadedPipeline.transform(dataframe)

predictions.show(200)