{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis del Partido Apra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy\n",
    "#!pip install pymongo\n",
    "import json\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import configparser\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_datasets as tfds\n",
    "import pickle\n",
    "import funciones \n",
    "from funciones import (DIACRITICAL_VOWELS, SLANG, stop_words,SLANG_SP_SN,stop_words_p)\n",
    "from funciones import eliminarhtml,text_to_wordlist,text_to_wordlist_wc,encoding_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descargamos los datos de Twitter\n",
    "from tweepy import OAuthHandler\n",
    "#Claves del acceso\n",
    "consumer_key = 'eMcnfrsrAgghHJCCBdP8QStYj'\n",
    "consumer_secret = 'M2FwH7ARB8MK6hq0n8HTrVErWanAsTST0nkmw11VfvuMjn8fel'\n",
    "access_token = '587863980-j6aJNJaXotnCuYF5rBZ8myUYF8kCet61E5sgWWHC'\n",
    "access_token_secret = 'TbSQ6OVufSk0LH6iiRpSAJBwffggEOR2Ah1ToXRQghRIV'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api=tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True,parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos los datos en archivo JSON\n",
    "count = 3000\n",
    "date_since=\"2019-10-01\"\n",
    "search_words=\"Alianza por el progreso\"\n",
    "api = tweepy.API(auth)                                                                                                 \n",
    "results = [status._json for status in tweepy.Cursor(api.search, q=search_words, count=count,since=date_since, tweet_mode='extended', lang='es').items()]\n",
    "results\n",
    "with open('APPS1OK.json', 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twet_data= open('APPS1OK.json', 'r').read()\n",
    "twet = json.loads(twet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1619"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    with open('APPS1OK.json') as train_file:\n",
    "        dict_train = json.load(train_file, encoding='latin-1')\n",
    "    tweets = pd.DataFrame.from_dict(dict_train)\n",
    "    len(tweets.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Almacenamos los datos mas relevantes\n",
    "question_list = list()\n",
    "for question in tweets.source:\n",
    "  question_list.append(eliminarhtml(str(question).strip()))\n",
    "df = pd.DataFrame(question_list, columns =['source']) \n",
    "df['id_str']         = tweets['id_str']\n",
    "df['created_at']     = tweets['created_at']\n",
    "df['full_text']      = tweets['full_text']\n",
    "df['favorite_count'] = tweets['favorite_count']\n",
    "df['retweet_count']  = tweets['retweet_count']\n",
    "\n",
    "df_3sub=pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in tweets['user'].items() ]))\n",
    "df_3sub.reset_index(col_level=0)\n",
    "df3_cand=df_3sub.T\n",
    "\n",
    "df['screen_name']    = df3_cand['screen_name']\n",
    "df['location']       = df3_cand['location']\n",
    "df['full_text1']     = tweets['full_text']\n",
    "df.drop_duplicates('full_text', keep=\"last\", inplace=True)\n",
    "df.sort_index(inplace=True) \n",
    "\n",
    "dfx = pd.DataFrame()\n",
    "dfx['id_str'] =df['id_str']\n",
    "#dfx['full_text_i'] =df['full_text']\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "#Normalizamos el campo fecha\n",
    "df['created_at'] = pd.to_datetime(df.created_at)\n",
    "df['created_at'] = df['created_at'].dt.normalize()\n",
    "df['numero']=1\n",
    "df['created_at'] = df['created_at'].dt.strftime('%Y-%m-%d')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = list()\n",
    "for question in df.full_text:\n",
    "  question_list.append(text_to_wordlist(str(question).strip()))\n",
    "df1 = pd.DataFrame(question_list, columns =['full_text'])\n",
    "#df1['full_text_i']=dfx['full_text_i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizador/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "Dcnn2 = load_model(\"dcnn\")\n",
    "pred = df1.full_text.apply(tokenizer.encode)\n",
    "pred = tf.keras.preprocessing.sequence.pad_sequences(pred,\n",
    "                                                            value=0,\n",
    "                                                            padding=\"post\",\n",
    "                                                            maxlen=40)\n",
    "len(np.argmax(Dcnn2.predict(pred),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis de Sentimiento\n",
    "my_array=np.argmax(Dcnn2.predict(pred),axis=1)\n",
    "dfp = pd.DataFrame(my_array, columns = ['POS'])\n",
    "dfp['POS1'] = dfp['POS'].map({0:\"Negativo\", 1:\"Neutro\",2:\"Positivo\"})\n",
    "df['POS']=dfp['POS1']\n",
    "df['POS1']=dfp['POS1'].map({\"Negativo\":\"cant_tot_negativos\", \"Neutro\":\"cant_tot_neutro\",\"Positivo\":\"cant_tot_positivos\"})\n",
    "total_app = df.groupby(['POS1']).agg(\n",
    "                                  {'numero': 'sum'\n",
    "                                  }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analisis_sentimiento_app = total_app.T\n",
    "df_analisis_sentimiento_app.reset_index(drop=True,inplace=True)\n",
    "df_analisis_sentimiento_app = df_analisis_sentimiento_app.rename(columns={0:df_analisis_sentimiento_app.loc[0, 0]})\n",
    "df_analisis_sentimiento_app = df_analisis_sentimiento_app.rename(columns={1:df_analisis_sentimiento_app.loc[0, 1]})\n",
    "df_analisis_sentimiento_app = df_analisis_sentimiento_app.rename(columns={2:df_analisis_sentimiento_app.loc[0, 2]})\n",
    "df_analisis_sentimiento_app['cant_tot_extraidos']=len(df)\n",
    "df_analisis_sentimiento_app.drop([0],axis=0,inplace=True)\n",
    "#df_analisis_sentimiento_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stop_words = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = list()\n",
    "for question in df.full_text1:\n",
    "  question_list.append(text_to_wordlist_wc(str(question).strip()))\n",
    "df1 = pd.DataFrame(question_list, columns =['full_text1']) \n",
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = '' \n",
    "for val in df1.full_text1: \n",
    "    val = str(val) \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "    comment_words += \" \".join(tokens)+\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_word=word_tokenize(comment_words)\n",
    "#print(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 1066 samples and 2728 outcomes>\n"
     ]
    }
   ],
   "source": [
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)\n",
    "xd=fdist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis de tendencia app\n",
    "df_analisis_tendencia_app = pd.DataFrame(data=xd,columns=['termino','frecuencia'])\n",
    "source_df = df.groupby(('source')).numero.sum()\n",
    "source_sorted = sorted(source_df.items(), key=lambda x: x[1], reverse=True)\n",
    "source_t= pd.DataFrame(data=source_sorted,columns=['source','cantidad'])\n",
    "#df_analisis_tendencia_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_usuarios_app = df.groupby(['created_at','POS']).agg(\n",
    "                                  {'numero': 'sum'\n",
    "                                  }).reset_index()\n",
    "\n",
    "df_t_usuarios_app.rename(columns={'created_at': 'fecha', \n",
    "                                    'POS': 'sentimiento','numero':'tweet'}, inplace=True)\n",
    "#df_t_usuarios_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conectamos a la base de datos\n",
    "mongod_connect = 'mongodb://localhost:27017'\n",
    "client = MongoClient(mongod_connect)\n",
    "db =client['db_twitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x2b20dc1d80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creamos la tabla analisis_sentimiento_app\n",
    "analisis_sentimiento_app = db.analisis_sentimiento_app \n",
    "records = json.loads(df_analisis_sentimiento_app.T.to_json()).values()\n",
    "db.analisis_sentimiento_app.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_app =pd.DataFrame()\n",
    "df_t_app['id_str']         =df['id_str']\n",
    "df_t_app['screen_name']    =df['screen_name']\n",
    "df_t_app['created_at']     =df['created_at']\n",
    "df_t_app['full_text']      =df['full_text']\n",
    "df_t_app['favorite_count'] =df['favorite_count']\n",
    "df_t_app['retweet_count']  =df['retweet_count']\n",
    "df_t_app['location']       =df['location']\n",
    "df_t_app['source']         =df['source']\n",
    "df_t_app['pos']            =df['POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x2b25bf4a40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usuario_app = db.t_usuario_app\n",
    "records = json.loads(df_t_app.T.to_json()).values()\n",
    "db.t_app.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x2b20db9d00>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analisis_tendencia_app = db.analisis_tendencia_app\n",
    "records = json.loads(df_analisis_tendencia_app.T.to_json()).values()\n",
    "db.analisis_tendencia_app.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x2b20df5e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_usuarios_app = db.t_usuarios_app\n",
    "records = json.loads(df_t_usuarios_app.T.to_json()).values()\n",
    "db.t_usuarios_app.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
