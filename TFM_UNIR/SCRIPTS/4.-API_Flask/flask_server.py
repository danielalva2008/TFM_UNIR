# -*- coding: utf-8 -*-
"""flask_server.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B25q0CB_5MGslN7wtbYmn9JEoBO2giV3

# Importamos las librerias
"""


from nltk import TweetTokenizer
from sklearn.metrics import roc_curve,auc
import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
import re
from string import punctuation
import os
import matplotlib.pyplot as plt
from gensim.models import KeyedVectors
from sklearn.datasets import fetch_20newsgroups

from pyspark.sql import SparkSession
from pyspark import SparkContext
from pyspark.sql.types import *
from pyspark.sql import *
from pyspark.sql import Row
from pyspark.sql import functions as func
from pyspark.mllib.regression import LabeledPoint
from pyspark.ml.feature import  SQLTransformer
from pyspark.ml.evaluation import  BinaryClassificationEvaluator
from pyspark.mllib.evaluation import MulticlassMetrics
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.feature import (VectorAssembler,StringIndexer,StandardScaler,
                                OneHotEncoderEstimator,OneHotEncoder, 
                                VectorIndexer, IndexToString,
                                HashingTF, Tokenizer)
from pyspark.ml import Pipeline, PipelineModel
from pyspark.sql import Row
from pyspark.ml.classification import LinearSVC,OneVsRest,LogisticRegression

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "spark-2.4.0-bin-hadoop2.7"

import findspark
findspark.init("spark-2.4.0-bin-hadoop2.7")

"""las librerias de sklearn/tensorflow"""



"""Funciones auxiliares"""

DIACRITICAL_VOWELS = [('á','a'), ('é','e'), ('í','i'), ('ó','o'), ('ú','u'), ('ü','u')]
SLANG = [('d','de'), ('[qk]','que'), ('xo','pero'), ('xa', 'para'), ('[xp]q','porque'),('es[qk]', 'es que'),
              ('fvr','favor'),('(xfa|xf|pf|plis|pls|porfa)', 'por favor'), ('dnd','donde'), ('tb', 'también'),
              ('(tq|tk)', 'te quiero'), ('(tqm|tkm)', 'te quiero mucho'), ('x','por'), ('\+','mas'),
              ('piña','mala suerte'),('agarre','adulterio'),('ampay','verguenza'),('bacan','alegria'),
              ('bamba','falsificado'),('cabeceador','ladron'),('cabro','homosexual'),('cachaciento','burlon'),
              ('calabacita','tonta'),('caleta','secreto'),('cabro','homosexual'),('cana','carcel'),
              ('chucha','molestia'),('choro','ladron'),('conchán','conchudo'),('cutra','ilicito'),
              ('dark','horrible'),('lenteja','torpe'),('lorna','tonto'),('mancar','morir'),
              ('monse','tonto'),('lenteja','torpe'),('lorna','tonto'),('mancar','morir'),('piñata','mala suerte')
              ]

stop_words=['a', 'actualmente', 'adelante', 'además', 'afirmó', 'agregó', 'ahí', 'ahora',
    'cc', 'pa', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',
    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'al',
    'algo', 'algún', 'algún', 'alguna', 'algunas', 'alguno', 'algunos',
    'alrededor', 'ambos', 'ampleamos', 'añadió', 'ante', 'anterior', 'antes',
    'apenas', 'aproximadamente', 'aquel', 'aquellas', 'aquellos', 'aqui',
    'aquí', 'arriba', 'aseguró', 'así', 'atras', 'aún', 'aunque', 'ayer',
    'bajo', 'bastante', 'bien', 'buen', 'buena', 'buenas', 'bueno', 'buenos',
    'cada', 'casi', 'cerca', 'cierta', 'ciertas', 'cierto', 'ciertos', 'cinco',
    'comentó', 'como', 'cómo', 'con', 'conocer', 'conseguimos', 'conseguir',
    'considera', 'consideró', 'consigo', 'consigue', 'consiguen', 'consigues',
    'contra', 'cosas', 'creo', 'cual', 'cuales', 'cualquier', 'cuando',
    'cuanto', 'cuatro', 'cuenta', 'da', 'dado', 'dan', 'dar', 'de', 'debe',
    'deben', 'debido', 'decir', 'dejó', 'del', 'demás', 'dentro', 'desde',
    'después', 'dice', 'dicen', 'dicho', 'dieron', 'diferente', 'diferentes',
    'dijeron', 'dijo', 'dio', 'donde', 'dos', 'durante', 'e', 'ejemplo', 'el',
    'de', 'la', 'el', 'porfas', 't', 'p', 'd', 'est',
    'él', 'ella', 'ellas', 'ello', 'ellos', 'embargo', 'empleais', 'emplean',
    'emplear', 'empleas', 'empleo', 'en', 'encima', 'encuentra', 'entonces',
    'entre', 'era', 'eramos', 'eran', 'eras', 'eres', 'es', 'esa', 'esas',
    'ese', 'eso', 'esos', 'esta', 'ésta', 'está', 'estaba', 'estaban',
    'estado', 'estais', 'estamos', 'estan', 'están', 'estar', 'estará',
    'estas', 'éstas', 'este', 'éste', 'esto', 'estos', 'éstos', 'estoy',
    'estuvo', 'ex', 'existe', 'existen', 'explicó', 'expresó', 'fin', 'fue',
    'fuera', 'fueron', 'fui', 'fuimos', 'gran', 'grandes', 'gueno', 'ha',
    'haber', 'había', 'habían', 'habrá', 'hace', 'haceis', 'hacemos', 'hacen',
    'hacer', 'hacerlo', 'haces', 'hacia', 'haciendo', 'hago', 'han', 'hasta',
    'hay', 'haya', 'he', 'hecho', 'hemos', 'hicieron', 'hizo', 'hoy', 'hubo',
    'igual', 'incluso', 'indicó', 'informó', 'intenta', 'intentais',
    'intentamos', 'intentan', 'intentar', 'intentas', 'intento', 'ir', 'junto',
    'la', 'lado', 'largo', 'las', 'le', 'les', 'llegó', 'lleva', 'llevar',
    'lo', 'los', 'luego', 'lugar', 'manera', 'manifestó', 'más', 'mayor', 'me',
    'mediante', 'mejor', 'mencionó', 'menos', 'mi', 'mientras', 'mio', 'misma',
    'mismas', 'mismo', 'mismos', 'modo', 'momento', 'mucha', 'muchas', 'mucho',
    'muchos', 'muy', 'nada', 'nadie', 'ni', 'ningún', 'ninguna', 'ningunas',
    'ninguno', 'ningunos', 'nos', 'nosotras', 'nosotros', 'nuestra',
    'nuestras', 'nuestro', 'nuestros', 'nueva', 'nuevas', 'nuevo', 'nuevos',
    'nunca', 'o', 'ocho', 'otra', 'otras', 'otro', 'otros', 'para', 'parece',
    'parte', 'partir', 'pasada', 'pasado', 'pero', 'pesar', 'poca', 'pocas',
    'poco', 'pocos', 'podeis', 'podemos', 'poder', 'podrá', 'podrán', 'podria',
    'podría', 'podriais', 'podriamos', 'podrian', 'podrían', 'podrias',
    'poner', 'por', 'porque', 'por qué', 'posible', 'primer', 'primera',
    'primero', 'primeros', 'principalmente', 'propia', 'propias', 'propio',
    'propios', 'próximo', 'próximos', 'pudo', 'pueda', 'puede', 'pueden',
    'puedo', 'pues', 'que', 'qué', 'quedó', 'queremos', 'quien', 'quién',
    'quienes', 'quiere', 'realizado', 'realizar', 'realizó', 'respecto',
    'sabe', 'sabeis', 'sabemos', 'saben', 'saber', 'sabes', 'se', 'sea',
    'sean', 'según', 'segunda', 'segundo', 'seis', 'señaló', 'ser', 'será',
    'serán', 'sería', 'si', 'sí', 'sido', 'siempre', 'siendo', 'siete',
    'sigue', 'siguiente', 'sin', 'sino', 'sobre', 'sois', 'sola', 'solamente',
    'solas', 'solo', 'sólo', 'solos', 'somos', 'son', 'soy', 'su', 'sus',
    'tal', 'también', 'tampoco', 'tan', 'tanto', 'tendrá', 'tendrán', 'teneis',
    'tenemos', 'tener', 'tenga', 'tengo', 'tenía', 'tenido', 'tercera',
    'tiempo', 'tiene', 'tienen', 'toda', 'todas', 'todavía', 'todo', 'todos',
    'total', 'trabaja', 'trabajais', 'trabajamos', 'trabajan', 'trabajar',
    'trabajas', 'trabajo', 'tras', 'trata', 'través', 'tres', 'tuvo', 'tuyo',
    'tu', 'te', 'pq', 'mas', 'qie', 'us', 'has', 'ti', 'ahi', 'mis', 'tus',
    'do', 'X', 'Ven', 'mo', 'Don', 'dia', 'PT', 'sua', 'q', 'x', 'i', 
    'última', 'últimas', 'ultimo', 'último', 'últimos', 'un', 'una', 'unas',
    'uno', 'unos', 'usa', 'usais', 'usamos', 'usan', 'usar', 'usas', 'uso',
    'usted', 'va', 'vais', 'valor', 'vamos', 'van', 'varias', 'varios', 'vaya',
    'veces', 'ver', 'verdad', 'verdadera', 'verdadero', 'vez', 'vosotras',
    'n', 's', 'of', 'c', 'the', 'm', 'qu', 'to', 'as', 'is',
    'asi', 'via', 'sera', 'tambien', 'vosotros', 'voy', 'y', 'ya', 'yo']

def text_to_wordlist(text, remove_stop_words=True, stem_words=False):
    # limpiar el  texto
    text = str(text).strip()
    #remplazar los acentos
    for s,t in DIACRITICAL_VOWELS:
        text = re.sub(r'{0}'.format(s), t, text)
   #remplazar el SLANG
    for s,t in SLANG:
        text = re.sub(r'\b{0}\b'.format(s), t, text)
    text = re.sub(r"@[A-Za-z0-9]+", ' ', text)
    text = re.sub(r"[^A-Za-z0-9]", " ", text)
    text = re.sub(r"\'s", " ", text)
    text = re.sub(r"\0s", "0", text)
    text = re.sub(r" 9 11 ", "911", text)
    text = re.sub(r"e-mail", "email", text)
    text = re.sub(r"\0rs ", " rs ", text) 
    text = re.sub(r"gps", "GPS", text)
    text = re.sub(r"gst", "GST", text)
   #convertir a minusculas
    text = text.lower()
    # Remove punctuation from text
    text = ''.join([c for c in text if c not in punctuation])

    # remover stop words
    if remove_stop_words:
        text = text.split()
        text = [w for w in text if not w in stop_words]
        text = " ".join(text)
    return(text)

"""The server:"""


# Commented out IPython magic to ensure Python compatibility.
from flask import Flask
from flask_restful import Api, Resource, reqparse
from sklearn.externals import joblib
try:
#     %tensorflow_version 2.x
except Exception:
    pass
import tensorflow as tf

from tensorflow.keras.models import load_model
import tensorflow_datasets as tfds
import pickle

from flask_ngrok import run_with_ngrok

MAX_LEN = 40

patch_rrnn = ''
patch_rcnn = ''
patch_svm  = ''
patch_tokenizador = ''

findspark.init("spark-2.4.0-bin-hadoop2.7")

APP = Flask(__name__)
API = Api(APP, catch_all_404s=True)

dicc_clases = {0: "Negativo", 1: "Neutro", 2: "Positivo"}

with open(patch_tokenizador, 'rb') as handle:
    tokenizer = pickle.load(handle)


class Predict(Resource):

    @staticmethod
    def post():
      try:
        parser = reqparse.RequestParser()
        parser.add_argument('texto')
        parser.add_argument('modelo')
        args = parser.parse_args()  #

        texto_predecir = text_to_wordlist(args['texto'])  #         
        model_select = args['modelo'] 

        if model_select == 'svm':  
          df_texto = pd.DataFrame({'full_text':texto_predecir}, index=[0])
          spark = SparkSession.builder.master("local[*]").appName("Pricing").getOrCreate()
          loadedPipeline = PipelineModel.read().load(patch_svm)        
          dataframe=spark.createDataFrame(df_texto, ["text"])\
               .withColumn("id", func.monotonically_increasing_id())\
               .dropDuplicates()
          predictions = loadedPipeline.transform(dataframe)
          prediccion = predictions.select('prediction').collect()[0]["prediction"]

        elif model_select == 'rrnn':  
          Rrnn = load_model(patch_rrnn)
          texto_array = np.array([tokenizer.encode(texto_predecir)])
          texto_padded = tf.keras.preprocessing.sequence.pad_sequences(texto_array,
                                                            value=0,
                                                            padding="post",
                                                            maxlen=MAX_LEN)
          prediccion = np.argmax(Rrnn.predict(texto_padded))   
        else:
          Dcnn = load_model(patch_rcnn)
          texto_array = np.array([tokenizer.encode(texto_predecir)])
          texto_padded = tf.keras.preprocessing.sequence.pad_sequences(texto_array,
                                                            value=0,
                                                            padding="post",
                                                            maxlen=MAX_LEN)
          prediccion = np.argmax(Dcnn.predict(texto_padded))

        out = {'Prediction': dicc_clases[int(prediccion)]}
      except Exception as e:
        return {'error':'Ha ocurrido un error'}, 500        
      return out, 200


API.add_resource(Predict, '/predict')

if __name__ == '__main__':
  APP.run()



